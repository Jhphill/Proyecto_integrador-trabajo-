# =================================================================================
# PROYECTO INTEGRADOR I: LIMPIEZA Y PREPARACI√ìN AVANZADA DE DATOS DE AUTOS EL√âCTRICOS
# =================================================================================

# --- 1. CONFIGURACI√ìN E IMPORTACIONES ---
import pandas as pd
import numpy as np
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy.stats import iqr
import matplotlib.pyplot as plt
import seaborn as sns

# Nombres de archivos
FILE_PATH = "C:\\Users\\juanf\\OneDrive\\Documentos\\Proyecto_integrador-trabajo-\\IEA Global EV Data 2024 full.csv"
OUTPUT_FILE = "df_final_preparado.csv"

# Columnas clave para la limpieza avanzada
IMPUTATION_COLS = [
    'price', 'range_km', 'charging_time', 'sales_volume', 'co2_saved',
    'battery_capacity', 'energy_efficiency', 'weight_kg',
    'number_of_seats', 'motor_power', 'distance_traveled'
]
CATEGORICAL_COLS = ['region', 'parameter', 'mode', 'powertrain']

# FIX: Definici√≥n de columnas de Outliers movida a la Secci√≥n 1 para evitar NameError
outlier_check_cols = ['price', 'range_km', 'battery_capacity', 'weight_kg', 'motor_power']

print("--- INICIO DEL PROCESO DE LIMPIEZA AVANZADA ---")

# --- 2. PASO 1 & 2: LIMPIEZA INICIAL, FILTRADO Y CODIFICACI√ìN ---

# 2.1. Carga de datos y Manejo de Duplicados
try:
    df = pd.read_csv(FILE_PATH)
except FileNotFoundError:
    print(f"ERROR: No se encontr√≥ el archivo '{FILE_PATH}'.")
    exit()

initial_rows = len(df)
df_dups_count = df.duplicated().sum()
df.drop_duplicates(inplace=True)

# 2.2. Filtrado Hist√≥rico (Esencial para la precisi√≥n de los modelos)
df_historical = df[df['category'] == 'Historical'].copy()
df_historical.drop(columns=['unit', 'category'], inplace=True)

# C√ÅLCULO DE M√âTRICAS INICIALES PARA EL RESUMEN
rows_after_initial_cleaning = len(df_historical)
reduction_percentage = ((initial_rows - rows_after_initial_cleaning) / initial_rows) * 100

# C√ÅLCULO DE NULOS PROMEDIO ANTES DE MICE (para la tabla de impacto)
nulls_pre_imputation = df_historical[IMPUTATION_COLS].isnull().sum()
# Buscamos el porcentaje de nulos en las columnas que s√≠ deb√≠an tener datos (las de especificaciones)
# Si no tienen nulos, el max es 0.
max_null_count = nulls_pre_imputation[outlier_check_cols].max()
max_null_percentage = (max_null_count / len(df_historical)) * 100
max_null_percentage_str = f"{max_null_percentage:.1f}%" if max_null_percentage > 0 else "0.0%"


# Guardamos las variables categ√≥ricas originales antes de la codificaci√≥n
df_context = df_historical[CATEGORICAL_COLS + ['year', 'value']].reset_index(drop=True)

# 2.3. Codificaci√≥n One-Hot Encoding (Necesario para MICE y PCA)
df_encoded = pd.get_dummies(df_historical, columns=CATEGORICAL_COLS, drop_first=True, dtype=int)
print(f"DataFrame codificado creado. Columnas totales: {df_encoded.shape[1]}")


# --- 3. PASO 3: IMPUTACI√ìN AVANZADA (MAECI/MICE) ---

# Identificamos todas las columnas num√©ricas para la imputaci√≥n
cols_to_impute = df_encoded.select_dtypes(include=np.number).columns.tolist()

# Inicializar IterativeImputer (implementaci√≥n de MICE/MAECI)
mice_imputer = IterativeImputer(random_state=42, max_iter=10)

# Aplicar la imputaci√≥n MICE al subconjunto de columnas num√©ricas
df_imputed_array = mice_imputer.fit_transform(df_encoded[cols_to_impute])

# Reconstruir el DataFrame imputado
df_imputed = pd.DataFrame(df_imputed_array, columns=cols_to_impute)
print("\n--- Imputaci√≥n MAECI/MICE Completada ---")


# --- 4. PASO 4: MANEJO DE OUTLIERS (IQR CAPPING) ---

# !!! PUNTO CLAVE: Guardar el DataFrame antes del capping para la comparaci√≥n real "Antes vs Despu√©s"
df_imputed_pre_capping = df_imputed[outlier_check_cols].copy()
total_outliers_ajustados = 0

for col in outlier_check_cols:
    # 4.1. Detecci√≥n: Calcular Q1, Q3 y IQR
    Q1 = df_imputed[col].quantile(0.25)
    Q3 = df_imputed[col].quantile(0.75)
    IQR_val = Q3 - Q1

    # 4.2. Manejo: Definir l√≠mites para el "Capping" (ajuste)
    lower_limit = Q1 - 1.5 * IQR_val
    upper_limit = Q3 + 1.5 * IQR_val
    
    # Contar outliers antes de aplicar Capping
    outliers_count = (df_imputed[col] < lower_limit).sum() + (df_imputed[col] > upper_limit).sum()
    total_outliers_ajustados += outliers_count

    # Aplicar Capping: Reemplazar valores fuera de los l√≠mites por los l√≠mites
    df_imputed[col] = np.where(df_imputed[col] < lower_limit, lower_limit, df_imputed[col])
    df_imputed[col] = np.where(df_imputed[col] > upper_limit, upper_limit, df_imputed[col])

print("\n--- Manejo de Outliers (Capping con IQR) Completado ---")


# --- 5. PASO 4.2: AN√ÅLISIS DE COMPONENTES PRINCIPALES (PCA) ---

# Variables a estandarizar y usar en PCA
pca_features = outlier_check_cols # Ya definido

# 5.1. Estandarizaci√≥n de los datos (Escalamiento)
scaler = StandardScaler()
df_pca_scaled = scaler.fit_transform(df_imputed[pca_features])

# 5.2. Aplicaci√≥n de PCA
# Reducimos a 2 componentes para la visualizaci√≥n.
pca = PCA(n_components=2)
principal_components = pca.fit_transform(df_pca_scaled)

# 5.3. Integraci√≥n de Componentes al DataFrame
df_imputed['PC1_Car_Specs'] = principal_components[:, 0]
df_imputed['PC2_Car_Specs'] = principal_components[:, 1]

print(f"\n--- PCA Completado ---")
variance_explained = pca.explained_variance_ratio_.sum()
print(f"Varianza total explicada (PC1+PC2): {variance_explained:.2f}")


# --- 6. PREPARACI√ìN DEL DATASET FINAL ---

# Reconstruimos el DataFrame final uniendo las nuevas columnas PCA con las columnas de contexto.
df_final = df_context.copy()

# Copiamos las variables imputadas, ajustadas (outliers) y usadas en PCA
for col in IMPUTATION_COLS: # Usamos IMPUTATION_COLS para incluir todas las imputadas
    if col in df_imputed.columns:
        # Aseguramos que los √≠ndices se alineen correctamente
        df_final[col] = df_imputed[col].reset_index(drop=True)
        
# A√±adimos los componentes principales
df_final['PC1_Car_Specs'] = df_imputed['PC1_Car_Specs'].reset_index(drop=True)
df_final['PC2_Car_Specs'] = df_imputed['PC2_Car_Specs'].reset_index(drop=True)

# Limpieza final de posibles filas duplicadas creadas por el manejo de √≠ndices
df_final.drop_duplicates(inplace=True)

# Guardar el Data Set Limpio para la entrega
df_final.to_csv(OUTPUT_FILE, index=False)

print("\n--- ¬°PROCESO FINALIZADO CON √âXITO! ---")
print(f"Data Set Limpio y Preparado guardado en: {OUTPUT_FILE}")
print(f"Filas finales listas para Streamlit: {len(df_final)}")

# ==============================================================================
# üåü 8. RESUMEN EJECUTIVO DE IMPACTO Y MEJORAS üåü
# ==============================================================================

print("\n" + "="*50)
print("## üéØ *IMPACTO Y MEJORAS LOGRADAS*")
print("\n### *‚úÖ Resumen de Limpieza Inicial*")
print(f"Filas iniciales: {initial_rows} ‚Üí Filas despu√©s de limpieza inicial: {rows_after_initial_cleaning}")
print(f"(Reducci√≥n del {reduction_percentage:.2f}% por eliminaci√≥n de duplicados y filtrado)")
print("\n### *‚úÖ Calidad de Datos Mejorada*")
print("| M√©trica | Antes | Despu√©s | Mejora |")
print("|---------|-------|---------|--------|")
print(f"| *Datos Faltantes* | {max_null_percentage_str} | 0% | *100%* |")
print(f"| *Outliers Extremos* | {total_outliers_ajustados} registros | 0 | *Ajustados* |")
print("| *Consistencia* | Variable | Alta | *‚ñ≤‚ñ≤‚ñ≤* |")
print("| *Preparaci√≥n ML* | No | S√≠ | *‚úÖ* |")
print(f"\n*Nota: La m√©trica de Datos Faltantes representa el peor caso (m√°ximo nulo) de las columnas clave imputadas.*")
print("="*50)

# --- 7. AN√ÅLISIS EXPLORATORIO DE DATOS (EDA) Y VISUALIZACIONES PARA EL INFORME ---

print("\n--- 7. Generando Visualizaciones Clave para el Informe ---")

# Configuraci√≥n b√°sica de Seaborn/Matplotlib
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['figure.titlesize'] = 16
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12

# ==============================================================================
# 7.1. BOXPLOTS: COMPARACI√ìN "ANTES VS. DESPU√âS" DEL CAPPING DE OUTLIERS üí•
# ==============================================================================

print("\nGenerando Boxplots de comparaci√≥n (Antes vs. Despu√©s del Capping).")

cols_compare = ['price', 'battery_capacity']
df_comparison = pd.DataFrame()

for col in cols_compare:
    data_pre = df_imputed_pre_capping[col].rename(col)
    data_pre = pd.DataFrame({
        'Variable': col,
        'Valor': data_pre,
        'Estado': '1. Antes del Capping'
    })
    
    data_post = df_final[col].rename(col)
    data_post = pd.DataFrame({
        'Variable': col,
        'Valor': data_post,
        'Estado': '2. Despu√©s del Capping'
    })
    
    df_comparison = pd.concat([df_comparison, data_pre, data_post], ignore_index=True)

plt.figure(figsize=(14, 6))
sns.boxplot(x='Variable', y='Valor', hue='Estado', data=df_comparison, 
            palette={'1. Antes del Capping': 'skyblue', '2. Despu√©s del Capping': 'lightcoral'})
plt.title(f'Comparaci√≥n de Distribuci√≥n: Antes vs. Despu√©s del Capping de Outliers (IQR)', fontsize=16)
plt.xlabel('')
plt.ylabel('Valor de la M√©trica')
plt.legend(title='Estado del Dato')
plt.tight_layout()
plt.savefig('comparacion_boxplot_outliers.png')
# plt.show()
print("Boxplot de comparaci√≥n Antes vs. Despu√©s generado.")

# ==============================================================================
# 7.2. DISTRIBUCIONES: Histograma de Price (Post-Limpieza) üìâ
# ==============================================================================

plt.figure(figsize=(10, 5))
sns.histplot(df_final['price'], bins=30, kde=True, color='darkgreen')
plt.title('Distribuci√≥n de "price" (Imputado y con Outliers Ajustados)', fontsize=14)
plt.xlabel('Precio (USD) Ajustado', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)
plt.tight_layout()
plt.savefig('distribucion_precio_limpio.png')
# plt.show()
print("Histograma de Precio generado.")


# ==============================================================================
# 7.3. MATRIZ DE CORRELACI√ìN (GR√ÅFICO DE CALOR) üî•
# ==============================================================================

# Matriz de correlaci√≥n para las variables clave despu√©s de la limpieza
correlation_matrix = df_final[IMPUTATION_COLS].corr()

plt.figure(figsize=(12, 10))
sns.heatmap(
    correlation_matrix,
    annot=True,
    fmt=".2f",
    cmap='coolwarm',
    linewidths=.5,
    cbar_kws={'label': 'Coeficiente de Correlaci√≥n'}
)
plt.title('Matriz de Correlaci√≥n de Variables Num√©ricas Clave (Post-Limpieza)', fontsize=16)
plt.tight_layout()
plt.savefig('matriz_correlacion.png')
# plt.show()
print("Matriz de Correlaci√≥n generada.")

# ==============================================================================
# 7.4. VISUALIZACI√ìN DE COMPONENTES PRINCIPALES (PCA) üìä
# ==============================================================================

plt.figure(figsize=(12, 8))
# Usamos 'region' para colorear los puntos
scatter = sns.scatterplot(
    x='PC1_Car_Specs',
    y='PC2_Car_Specs',
    hue='region', # Muestra la segmentaci√≥n por regiones
    data=df_final,
    palette='Spectral',
    alpha=0.7,
    s=70
)

plt.title('PCA - Representaci√≥n de Especificaciones de Autos El√©ctricos por Regi√≥n', fontsize=16)
plt.xlabel(f'Componente Principal 1 (PC1) - Varianza Explicada: {pca.explained_variance_ratio_[0]:.2%}', fontsize=12)
plt.ylabel(f'Componente Principal 2 (PC2) - Varianza Explicada: {pca.explained_variance_ratio_[1]:.2%}', fontsize=12)
plt.legend(title='Regi√≥n', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
plt.savefig('pca_car_specs.png')
# plt.show()
print("PCA Scatter Plot generado.")

# ==============================================================================
# 7.5. PAIR PLOT: Relaci√≥n Multivariada entre Variables Clave üîÑ
# ==============================================================================

print("\nGenerando Pair Plot de las especificaciones clave (puede tardar un poco)...")
# El Pair Plot genera un gr√°fico de dispersi√≥n para cada par de variables.
pair_cols = ['price', 'range_km', 'battery_capacity', 'weight_kg']

# Reducimos la muestra para que el gr√°fico no tarde demasiado
df_sample = df_final[pair_cols].sample(n=min(5000, len(df_final)), random_state=42)

sns.pairplot(df_sample, diag_kind='kde', plot_kws={'alpha': 0.6, 's': 5})
plt.suptitle('Pair Plot de Especificaciones Clave (Post-Limpieza)', y=1.02, fontsize=16)
plt.savefig('pair_plot_specs.png')
# plt.show()
print("Pair Plot generado.")

# ==============================================================================
# 7.6. AN√ÅLISIS DE TENDENCIAS POR MODO (VENTAS HIST√ìRICAS) üìà
# ==============================================================================

# Agrupar las ventas por a√±o y modo (Cars, Buses, Vans, Trucks)
sales_trend = df_final[df_final['value'].notna()].groupby(['year', 'mode']).agg(
    total_value=('value', 'sum') # 'value' representa EV stock/sales/etc.
).reset_index()

plt.figure(figsize=(12, 6))
sns.lineplot(
    data=sales_trend,
    x='year',
    y='total_value',
    hue='mode',
    marker='o',
    palette='tab10'
)

plt.title('Tendencia Hist√≥rica Agregada de la M√©trica "Value" por Modo', fontsize=14)
plt.xlabel('A√±o', fontsize=12)
plt.ylabel('Valor Agregado (Stock/Ventas, etc.)', fontsize=12)
plt.legend(title='Modo', loc='upper left')
plt.tight_layout()
plt.savefig('tendencia_ventas_historicas.png')
# plt.show()
print("Gr√°fico de Tendencia Hist√≥rica generado.")

# ==============================================================================
# 7.7. BOXPLOTS DE VARIABLES CLAVE (POST-LIMPIEZA) üì¶
# ==============================================================================
print("\nGenerando Boxplots individuales de variables clave (Post-Limpieza).")
plt.figure(figsize=(15, 10))
for i, col in enumerate(outlier_check_cols):
    plt.subplot(2, 3, i + 1)
    sns.boxplot(y=df_final[col], color='lightcoral')
    plt.title(f'Distribuci√≥n de "{col}" (Post-Capping)', fontsize=12)
    plt.ylabel(col)
plt.tight_layout()
plt.savefig('boxplots_post_capping_individual.png')
# plt.show()
print("Boxplots individuales Post-Limpieza generados.")

print("\n--- Visualizaciones completadas para el Informe de Limpieza. ---")